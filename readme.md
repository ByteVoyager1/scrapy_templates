# Руководство по созданию Scrapy-парсера

## Требования

### 1. Версии
- Python >= 3.9
- Scrapy == 2.11
- Poetry как менеджер зависимостей

### 2. Структура проекта
- Проект должен быть организован в соответствии с [примером](#пример-парсера)
- Обязательное наличие файлов:
  - `pyproject.toml` и `poetry.lock` для зависимостей
  - `main.py` для запуска парсера (в соответствии с [примером](#пример-парсера))
  - `settings.py` для конфигурации
    - Использовать относительные импорты
    - Допускаются импорты от корня проекта
    - Вручную настроить параметр ALLOWED_HOSTS на хосты запрашиваемого ресурса

### 3. Основные компоненты

- Класс парсера в [main.py](https://github.com/ByteVoyager1/scrapy_templates/blob/main/example/apple_pro/main.py) должен наследовать `CrawlerProtocol`
- Обязательная реализация всех методов протокола как в [примере](#пример-парсера)
- Каждый Spider должен быть независимым по умолчанию, а в случае зависимости между Spider'ами их связанность должна быть реализована в main.py
- [Scrapy Items](https://docs.scrapy.org/en/latest/topics/items.html) должны быть реализованы как dataclass
- Название Spider'ов должно состоять только из букв ([A-Za-z]*) 
- Парсер должен успевать отработать за 6 часов

#### Импорты
- Использовать относительные импорты
- Допускаются импорты от корня проекта

### 4. Дополнительные компоненты
- **Middleware/Extensions**: 
  - Размещать в отдельных модулях (`/middlewares`, `/extensions`)
  - Приоритет middleware в диапазоне [200, 499]
- **Rate Limiter** (опционально):
  - Если требуется ограничение запросов, явно указать на это при передаче проекта

### 5. Линтинг и форматирование
- Обязательное использование black/isort/flake8
    - Конфигурационные файлы лежат в [примере](#пример-парсера)
- Все проверки должны проходить без ошибок
- Отсутствие deprecated настроек в `settings.py`

## Порядок разработки

### 1. Подготовка проекта 
1. Создайте новый проект с использованием Poetry.
У вас должна получиться примерно такая структура проекта:
```
scrapy_test
├── __init__.py
├── extensions
│   └── __init__.py
├── main.py
├── middlewares
│   └── __init__.py
├── pipelines.py
├── settings.py
├── spiders
│   └── __init__.py
└── utils
    └── __init__.py
```
2. Добавьте необходимые зависимости в `pyproject.toml`

### 2. Разработка компонентов
1. Создайте классы спайдеров в `spiders/your_spider.py`
2. Определите `name`, `start_urls` и методы парсинга
3. Создайте dataclass для items в `items.py`
4. Сделайте реализацию вашего Spider в `main.py`

### 3. Особенности реализации [main.py](https://github.com/ByteVoyager1/scrapy_templates/blob/main/example/apple_pro/main.py)
- Декорируйте класс `@dataclass`
- Сохраните логику работы метода [.run_crawler()](https://github.com/ByteVoyager1/scrapy_templates/blob/main/example/apple_pro/main.py#L12)
- Добавьте [вызов](https://github.com/ByteVoyager1/scrapy_templates/blob/main/example/apple_pro/main.py#L13) вашего Spider в метод `run_crawler()`

### 4. Настройка проекта
1. Настройте `settings.py`
2. Добавьте необходимые middleware и pipeline
3. Установите правильные приоритеты для middleware

### 5. Тестирование
- Проверьте полный цикл работы парсера
- Выполните валидацию собираемых данных
- Протестируйте pipeline и middleware
- Проверьте работу кэширования

### 6. Финальная проверка
- Проверьте парсер на соответствие всем требованиям
- Убедитесь в отсутствии deprecated настроек
- Проверьте корректность импортов
- Проведите парсер через форматирование/линтинг

## Советы по разработке

- Разделяйте логику парсинга на маленькие методы с понятными названиями
- Документируйте неочевидные решения в коде
- Добавляйте type hints для всех методов и классов
- Не добавляйте логи без надобности - они не нужны
- Установите настройку [`CONCURRENT_REQUESTS = 1`](https://docs.scrapy.org/en/latest/topics/settings.html#concurrent-requests) для удобства отладки

## Пример парсера


### Базовый шаблон
- [Scrapy Template](https://github.com/ByteVoyager1/scrapy_templates) - репозиторий с базовым шаблоном и структурой проекта для создания парсеров

### Что вы найдете в шаблоне:
- Базовую структуру Scrapy проекта
- Пример Spider'а для [apple-pro.ru](https://apple-pro.ru/)
- Примеры Items в формате dataclass
- Настройки для линтеров (black/isort/flake8)
- Базовые настройки settings.py
